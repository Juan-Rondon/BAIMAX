"""
ğŸ§½ğŸ¤– bAImax - Sistema HÃ­brido de AnÃ¡lisis Inteligente de Salud PÃºblica
=====================================================================

Desarrollado para SENASOFT 2025
Autor: Proyecto bAImax
"""

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.pipeline import Pipeline
import pickle
import warnings
warnings.filterwarnings('ignore')

class bAImaxClassifier:
    """
    ğŸ§  Clasificador inteligente de gravedad de problemas de salud
    
    Utiliza TF-IDF + Machine Learning para clasificar automÃ¡ticamente
    la gravedad de reportes ciudadanos como GRAVE o MODERADO
    """
    
    def __init__(self, modelo_tipo='logistic'):
        self.modelo_tipo = modelo_tipo
        self.pipeline = None
        self.metricas = {}
        self.esta_entrenado = False
        
    def entrenar(self, dataset_path='src/data/dataset_normalizado.csv'):
        """
        ğŸ¯ Entrena el modelo con nuestro dataset optimizado
        """
        print("ğŸ§½ bAImax iniciando entrenamiento...")
        
        # Cargar dataset
        df = pd.read_csv(dataset_path)
        print(f"ğŸ“Š Dataset cargado: {len(df)} registros")
        
        # Preparar datos
        X = df['Comentario'].fillna('')
        y = df['Nivel_gravedad']
        
        print(f"ğŸ¯ DistribuciÃ³n de clases:")
        print(f"   GRAVE: {sum(y == 'GRAVE')} registros")
        print(f"   MODERADO: {sum(y == 'MODERADO')} registros")
        
        # Split train/test
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # Crear pipeline segÃºn tipo de modelo
        if self.modelo_tipo == 'logistic':
            modelo = LogisticRegression(random_state=42, max_iter=1000)
        else:
            modelo = RandomForestClassifier(random_state=42, n_estimators=100)
            
        self.pipeline = Pipeline([
            ('tfidf', TfidfVectorizer(
                max_features=1000,
                ngram_range=(1, 2),
                stop_words=None  # Mantenemos palabras en espaÃ±ol
            )),
            ('modelo', modelo)
        ])
        
        # Entrenar
        print("ğŸ¤– Entrenando modelo...")
        self.pipeline.fit(X_train, y_train)
        
        # Evaluar
        y_pred = self.pipeline.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        
        # Cross-validation
        cv_scores = cross_val_score(self.pipeline, X, y, cv=5, scoring='accuracy')
        
        self.metricas = {
            'accuracy': accuracy,
            'cv_mean': cv_scores.mean(),
            'cv_std': cv_scores.std(),
            'clasificacion': classification_report(y_test, y_pred, output_dict=True),
            'confusion_matrix': confusion_matrix(y_test, y_pred)
        }
        
        self.esta_entrenado = True
        
        print(f"âœ… Modelo entrenado exitosamente!")
        print(f"   PrecisiÃ³n: {accuracy:.3f}")
        print(f"   CV Score: {cv_scores.mean():.3f} (Â±{cv_scores.std():.3f})")
        
        return self
    
    def predecir(self, comentario):
        """
        ğŸ”® Predice la gravedad de un comentario
        """
        if not self.esta_entrenado:
            raise ValueError("El modelo debe ser entrenado primero")
            
        # PredicciÃ³n
        prediccion = self.pipeline.predict([comentario])[0]
        probabilidades = self.pipeline.predict_proba([comentario])[0]
        
        # Mapear probabilidades a clases
        clases = self.pipeline.classes_
        prob_dict = dict(zip(clases, probabilidades))
        
        return {
            'gravedad': prediccion,
            'confianza': max(probabilidades),
            'probabilidades': prob_dict
        }
    
    def predecir_lote(self, comentarios):
        """
        ğŸ“¦ Predice mÃºltiples comentarios a la vez
        """
        if not self.esta_entrenado:
            raise ValueError("El modelo debe ser entrenado primero")
            
        predicciones = self.pipeline.predict(comentarios)
        probabilidades = self.pipeline.predict_proba(comentarios)
        
        resultados = []
        for i, comentario in enumerate(comentarios):
            prob_dict = dict(zip(self.pipeline.classes_, probabilidades[i]))
            resultados.append({
                'comentario': comentario,
                'gravedad': predicciones[i],
                'confianza': max(probabilidades[i]),
                'probabilidades': prob_dict
            })
            
        return resultados
    
    def obtener_metricas(self):
        """
        ğŸ“Š Retorna mÃ©tricas de evaluaciÃ³n del modelo
        """
        if not self.esta_entrenado:
            return "Modelo no entrenado"
            
        return self.metricas
    
    def guardar_modelo(self, path='src/data/baimax_modelo.pkl'):
        """
        ğŸ’¾ Guarda el modelo entrenado
        """
        if not self.esta_entrenado:
            raise ValueError("El modelo debe ser entrenado primero")
            
        with open(path, 'wb') as f:
            pickle.dump(self.pipeline, f)
        print(f"ğŸ’¾ Modelo guardado en: {path}")
    
    def cargar_modelo(self, path='src/data/baimax_modelo.pkl'):
        """
        ğŸ“ Carga un modelo previamente entrenado
        """
        try:
            with open(path, 'rb') as f:
                self.pipeline = pickle.load(f)
            self.esta_entrenado = True
            print(f"ğŸ“ Modelo cargado desde: {path}")
        except FileNotFoundError:
            print(f"âŒ Archivo no encontrado: {path}")

class bAImaxAnalyzer:
    """
    ğŸ“Š Analizador de datos para generar insights y estadÃ­sticas
    """
    
    def __init__(self, dataset_path='src/data/dataset_normalizado.csv'):
        self.df = pd.read_csv(dataset_path)
        print(f"ğŸ“Š Dataset cargado para anÃ¡lisis: {len(self.df)} registros")
    
    def estadisticas_generales(self):
        """
        ğŸ“ˆ Genera estadÃ­sticas generales del dataset
        """
        stats = {
            'total_registros': len(self.df),
            'problemas_unicos': self.df['Comentario'].nunique(),
            'ciudades': self.df['Ciudad'].nunique(),
            'personas_unicas': self.df['Nombre'].nunique(),
            'distribucion_gravedad': self.df['Nivel_gravedad'].value_counts().to_dict(),
            'distribucion_ciudades': self.df['Ciudad'].value_counts().head(10).to_dict(),
            'distribucion_temporal': self.df['Fecha del reporte'].str[:4].value_counts().to_dict(),
            'zona_rural_urbana': {
                'Rural': (self.df['Zona rural'] == 1).sum(),
                'Urbana': (self.df['Zona rural'] == 0).sum()
            }
        }
        return stats
    
    def top_problemas(self, top_n=10):
        """
        ğŸ” Obtiene los problemas mÃ¡s reportados
        """
        problemas = self.df.groupby('Comentario').agg({
            'Frecuencia_similar': 'first',
            'Personas_afectadas': 'first',
            'Nivel_gravedad': 'first',
            'Ciudad': lambda x: list(x.unique())
        }).sort_values('Frecuencia_similar', ascending=False).head(top_n)
        
        return problemas.to_dict('index')
    
    def analisis_por_ciudad(self):
        """
        ğŸ™ï¸ AnÃ¡lisis detallado por ciudad
        """
        ciudad_stats = self.df.groupby('Ciudad').agg({
            'Comentario': 'count',
            'Nivel_gravedad': lambda x: (x == 'GRAVE').sum(),
            'Zona rural': 'mean',
            'Acceso a internet': 'mean',
            'AtenciÃ³n previa del gobierno': 'mean'
        }).round(2)
        
        ciudad_stats.columns = ['Total_reportes', 'Reportes_graves', 'Pct_rural', 'Pct_internet', 'Pct_atencion_previa']
        return ciudad_stats.to_dict('index')

# FunciÃ³n de demostraciÃ³n
def demo_baimax():
    """
    ğŸ­ DemostraciÃ³n del sistema bAImax
    """
    print("ğŸ§½ğŸ¤– DEMO DEL SISTEMA bAImax")
    print("=" * 50)
    
    # Crear y entrenar clasificador
    clasificador = bAImaxClassifier(modelo_tipo='logistic')
    clasificador.entrenar()
    
    # Ejemplos de predicciÃ³n
    ejemplos = [
        "faltan mÃ©dicos en el centro de salud",
        "falta agua potable en varias casas",
        "las calles estÃ¡n muy oscuras y peligrosas",
        "necesitamos mÃ¡s bibliotecas pÃºblicas"
    ]
    
    print("\nğŸ”® Predicciones de ejemplo:")
    print("-" * 30)
    
    for ejemplo in ejemplos:
        resultado = clasificador.predecir(ejemplo)
        print(f"ğŸ“ '{ejemplo}'")
        print(f"   ğŸ¯ Gravedad: {resultado['gravedad']}")
        print(f"   ğŸª Confianza: {resultado['confianza']:.3f}")
        print()
    
    # MÃ©tricas del modelo
    print("ğŸ“Š MÃ©tricas del modelo:")
    metricas = clasificador.obtener_metricas()
    print(f"   PrecisiÃ³n: {metricas['accuracy']:.3f}")
    print(f"   CV Score: {metricas['cv_mean']:.3f}")
    
    # AnÃ¡lisis estadÃ­stico
    print("\nğŸ“ˆ AnÃ¡lisis estadÃ­stico:")
    analyzer = bAImaxAnalyzer()
    stats = analyzer.estadisticas_generales()
    print(f"   Total registros: {stats['total_registros']}")
    print(f"   Problemas Ãºnicos: {stats['problemas_unicos']}")
    print(f"   Ciudades: {stats['ciudades']}")
    
    # Guardar modelo
    clasificador.guardar_modelo()
    
    print("\nâœ¨ Â¡Demo completada exitosamente! âœ¨")
    return clasificador, analyzer

if __name__ == "__main__":
    demo_baimax()